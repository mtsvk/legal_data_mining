# legal_data_mining

Flujo de minerÃ­a de datos jurÃ­dicos para â€œfichas de jurisprudenciaâ€ (resÃºmenes de sanciones), aplicado como ejemplo a sanciones del GDPR extraÃ­das de [enforcementtracker.com](https://enforcementtracker.com) (CMS Law.Tax, CCâ€¯BYâ€‘NCâ€‘SAâ€¯4.0). Reproducible en Googleâ€¯Colab y tambiÃ©n ejecutable localmente como script Python.

---

## ğŸ“‚ Estructura del repositorio

```
/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pipeline_legal_data_mining_20250725.ipynb
â”œâ”€â”€ pipeline_legal_data_mining_20250725.py
â””â”€â”€ outputs/                       â† Generado tras ejecutar la pipeline, disponibles en https://github.com/mtsvk/legal_data_mining/blob/main/outputs.zip
    â”œâ”€â”€ config.json
    â”œâ”€â”€ gdpr_clean.parquet
    â”œâ”€â”€ gdpr_norm.parquet
    â”œâ”€â”€ embedding_prueba.npy
    â”œâ”€â”€ embeddings.npy
    â”œâ”€â”€ df_emb.parquet
    â”œâ”€â”€ df_clustered.parquet
    â”œâ”€â”€ silhouette.json
    â”œâ”€â”€ kmeans.joblib
    â”œâ”€â”€ cluster_profile.json
    â”œâ”€â”€ clusters_2d.png
    â”œâ”€â”€ clusters_2d.csv
    â””â”€â”€ general_insights.md
```

---

## ğŸ¯ Objetivo

- **Analizar** cientos de resÃºmenes de sanciones GDPR.
- **Limpiar** y **normalizar** el texto.
- **Generar embeddings** semÃ¡nticos con OpenAI.
- **Agrupar** documentos similares con **Kâ€‘Means**.
- **Perfilar** clusters y **visualizar** en 2D.
- **Generar insights** automÃ¡ticos con un LLM (OpenAI).

Este pipeline es totalmente **reproducible** y fÃ¡cilmente **adaptable** a otros datasets jurÃ­dicos o administrativos.

---

## ğŸ“‹ Requisitos

- Pythonâ€¯â‰¥â€¯3.8  
- Una **clave de API de OpenAI** (se usa para embeddings e insights)
- Internet (si ejecutas el notebook en Colab o deseas llamar a la API)
- Las siguientes librerÃ­as (listadas en `requirements.txt`):
  ```
  openai
  python-dotenv
  tqdm
  matplotlib
  scikit-learn
  joblib
  pandas
  numpy
  ```

---

## ğŸš€ InstalaciÃ³n

1. **Clonar este repositorio**  
   ```bash
   git clone https://github.com/mtsvk/legal_data_mining.git
   cd legal_data_mining
   ```

2. **Crear un entorno virtual** (opcional pero recomendado)  
   ```bash
   python -m venv .venv
   source .venv/bin/activate      # Linux/macOS
   .venv\Scripts\activate       # Windows
   ```

3. **Instalar dependencias**  
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar la API Key**  
   Define tu `OPENAI_API_KEY` en el entorno o crea un archivo `.env` con:
   ```
   OPENAI_API_KEY=tu_clave_aquÃ­
   ```

---

## ğŸ§© Uso

### 1. Notebook en Googleâ€¯Colab

1. Abre `pipeline_legal_data_mining_20250725.ipynb` en Colab.
2. Monta tu Google Drive (opcional) o sube tu CSV (`gdpr_fines.csv`).
3. Ejecuta celda a celda. El directorio `outputs/` se irÃ¡ llenando automÃ¡ticamente.

### 2. Ejecutar como script Python

```bash
python pipeline_legal_data_mining_20250725.py   --input_csv path/to/gdpr_fines.csv   --output_dir outputs/
```

El script estÃ¡ diseÃ±ado para correr todo el pipeline de un tirÃ³n, produciendo idÃ©nticos artefactos en `outputs/`.

---

## ğŸ”„ DescripciÃ³n de los pasos (Scripts)

- **Scriptâ€¯0 â€“ ConfiguraciÃ³n inicial**  
  Instala dependencias, fija semilla, crea `config.json` y hace un sanityâ€check de embeddings.

- **Scriptâ€¯1 â€“ Ingesta y limpieza bÃ¡sica**  
  Lee CSV, renombra columnas, elimina duplicados y genera `gdpr_clean.parquet`.

- **Scriptâ€¯2 â€“ Limpieza avanzada y stopwords**  
  Quita HTML/URLs, normaliza texto, aplica stopwords generales y de dominio, guarda `gdpr_norm.parquet`.

- **Scriptâ€¯3 â€“ Embeddings OpenAI**  
  Sanitiza textos, llama a la API de OpenAI en batches, guarda `embeddings.npy` y `df_emb.parquet`.

- **Scriptâ€¯4 â€“ Clustering Kâ€‘Means**  
  EvalÃºa silhouette para K=4â€¦16, selecciona K Ã³ptimo, entrena modelo, guarda `kmeans.joblib`, clusters y scores.

- **Scriptâ€¯5 â€“ Perfilado de clusters**  
  Tokeniza resÃºmenes, extrae topâ€‘terms y ejemplos, guarda `cluster_profile.json`.

- **Scriptâ€¯6 â€“ VisualizaciÃ³n 2D**  
  Proyecta embeddings a 2D con TruncatedSVD, grafica clusters, guarda PNG y CSV de coordenadas.

- **Scriptâ€¯7 â€“ Insights automÃ¡ticos**  
  Construye prompt con scores y perfiles, llama a GPT-3.5/4, genera informe en Markdown (`general_insights.md`).

---

## âš™ï¸ AdaptaciÃ³n a otros proyectos

1. Cambia el CSV de entrada (`--input_csv` o `cfg["dataset_csv"]`).
2. Ajusta el mapeo de columnas en el Scriptâ€¯1.
3. Modifica stopwords o parÃ¡metros de `TfidfVectorizer` en el Scriptâ€¯2.
4. Experimenta con otros algoritmos de clustering o proyecciones (PCA, UMAP).

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**.  
Los datos de enforcementtracker.com estÃ¡n bajo **CCâ€¯BYâ€‘NCâ€‘SAâ€¯4.0**.

---

Â¡Contribuciones y sugerencias bienvenidas! ğŸš€  
